# 前端破局AI：基于LangGraph+TypeScript构建智能体

## 背景
不知道大家有没有跟我一样的问题，在这个AI时代，我们该如何学习AI？

打开搜索网站搜索如何学习AI？肯定会得到类似这样的流程

1. 学习Python
2. 学习线性代数、微积分、概率统计
3. 学习机器学习
4. 学习深度学习
5. 大模型训练
...

作为一个非相关专业，毕业10年之久的开发看到这些一脸懵，不用入门直接放弃。

并不是说这种学习路线不对，而是不适合我这样的工程师去学习。

作为开发人员在技术上我们更贴近业务和产品的应用层，而不是去研究更核心的底层原理。



项目需要快速完成AI功能迭代，这个时候直接上手智能体开发显然更具性价比。

所以我推荐LangGraph框架，从构建第一个智能体开始，提前感受 AI 开发的乐趣与成就感。
跳过爬山的过程，自上而下，从项目实践出发，在工作中逐步深挖原理。


在这里你将得到什么？

- 了解 LangGraph 核心原理和基础功能
- 快速搭建一个约 100 行代码的支持联网查询的智能体示例，可在终端交互运行
- 更多项目想法转换智能体的思路，可拓展的



结合国家发文，2027年，新一代智能终端、智能体等应用普及率要超过70%；到2030年，智能经济要成为中国经济发展的重要增长极。



## 什么是LangGraph？

#### 发展历程
要讲LangGraph不得不先说下LangCahain。
2022年10月，在OpenAI的ChatGPT正式发布前夕，LangChain发布了它的首个稳定版本。

其核心思想是模块化与链式编排，通过提供Prompt Templates、Models、Agents、Memory等标准化组件，并利用“链”将它们组合起来，极大地简化了早期LLM应用的开发流程。

随着大模型能力的飞速进化，大模型不仅拥有极强的工具识别和调用能力，同时还逐步支持多工具的并联和串联调用。LangChain链式工作流模式灵活性不足，已逐渐满足不了越来越复杂智能体的开发需求，于是在2024年2月LangChain团队发布了`LangGraph`，
`LangGraph`定位就是作为LangChain底层编排层，其核心采用图结构来设计工作流，提供更细粒度的控制流的同时添加了状态管理、流式处理、持久执行、记忆、人机交互等功能。

经过多年的迭代开发，2025年10月LangChain 团队正式发布 LangChain 1.0 与 LangGraph 1.0两大框架的首个主要版本，这个标志着LangChain生态已经是可满足企业级生产部署的智能体框架。


#### LangGraph与LangChain的关系
LangChain 1.0 版本对底层链式结构和代理进行了彻底的重构。所有链式结构和代理现在都替换为一个基于 LangGraph 构建的高级抽象。

自此LangChain和LangGraph的定位已经很明确了。

- LangGraph ：一个 底层运行时框架 ，专为需要长期运行、可控且高定制化的生产级智能体设计。
- LangChain ：是LangGraph的高级抽象，是构建 AI 智能体的 最快方式 。提供标准的工具调用架构、供应商无关设计和可插拔的中间件系统，让开发者高效构建通用 Agent。



LangGraph和LangChain的最佳实践
1. 基于LangChain的`createAgent`函数快速构建智能体
2. 将LangChain的核心组件作为LangGraph的“组件库”，通过LangGraph节点和边将这些组件组织编排在一起，构建一个复杂的工作流和智能体系统。


## LangGraph核心思想

LangGraph 的核心在于其采用了图架构来设计智能体的工作流程。LangGraph 将智能体执行任务的过程，抽象为一个由节点（Node）和边（Edge）构成的**有向循环图（Directed Cyclic Graph）**。

理解 LangGraph，可以抓住以下几个关键点：

- 图结构工作流：在 LangGraph 中，应用逻辑被建模成一个有向图，由“节点”和“边”组成。节点代表一个具体的操作步骤，例如调用大语言模型、执行一个工具函数或进行条件判断。边则定义了这些节点之间的连接关系和执行顺序。
- 状态管理：这是 LangGraph 的核心。它会维护一个贯穿整个图的共享数据结构（State）。每个节点都可以读取当前状态，并返回对状态的更新，使信息在多步骤工作流中有效传递与累积。
- 支持循环与分支：LangGraph 原生支持循环和条件分支。工作流可以根据中间结果“绕回去”重新执行某些步骤，或选择不同的执行路径，这对于需要反复试错或决策的场景至关重要。

核心组件：

#### 节点（Node）类型
- **LLM 调用节点**: 负责与大型语言模型进行交互，执行推理任务
- **工具调用节点**: 允许智能体调用外部工具或 API，扩展能力边界
- **自定义函数节点**: 封装业务逻辑或数据处理逻辑
- **子图节点**: 提高代码模块化和可维护性

#### 边（Edge）类型
- **普通边**: 定义节点间的直接顺序执行关系
- **条件边**: 根据状态动态决定工作流程走向
- **入口点**: 定义工作流程的起始位置
- **条件入口点**: 根据初始状态动态选择起始节点

#### 状态（State）
状态是 LangGraph 的核心概念，扮演着多重角色：
- **上下文信息存储**: 记录对话历史、任务进度等
- **节点间数据传递**: 作为共享的数据容器
- **状态持久化**: 支持记忆能力和容错恢复
- **多智能体共享**: 实现智能体间协作

## LangChain核心组件
同时我们还需要了解LangChain的核心组件

#### 模型
模型是智能体的推理引擎。它们驱动智能体的决策过程，决定调用哪些工具、如何解释结果以及何时给出最终答案。
您选择的模型的质量和功能直接影响智能体的基本可靠性和性能。不同的模型擅长不同的任务
LangChain 的标准模型接口可让您访问许多不同的提供商[集成](https://docs.langchain.com/oss/javascript/integrations/providers/overview)。


#### 消息
消息是模型的基本上下文单元。它们代表模型的输入和输出，携带与 LLM 交互时表示对话状态所需的内容和元数据。LangChain 提供了一种适用于所有模型提供程序的标准消息类型，确保无论调用哪个模型，行为都保持一致。

```typescript
const messages = [
  { role: "system", content: "You are a poetry expert" },
  { role: "user", content: "Write a haiku about spring" },
  { role: "assistant", content: "Cherry blossoms bloom..." },
];
import { SystemMessage, HumanMessage, AIMessage } from "langchain";

const messages = [
  new SystemMessage("You are a poetry expert"),
  new HumanMessage("Write a haiku about spring"),
  new AIMessage("Cherry blossoms bloom..."),
];

```

#### 工具
工具是智能体的扩展能力。它们提供了一系列的函数，智能体可以调用这些函数来完成特定的任务，如搜索、计算、数据处理等。
工具是大模型调用以执行操作的组件。它们通过定义明确的输入和输出，使大模型能够与世界进行交互，从而扩展模型的功能。

#### 记忆
 记忆系统能够记住以往交互的信息。对于人工智能体而言，记忆至关重要，因为它使它们能够记住之前的交互，从反馈中学习，并适应用户偏好。随着人工智能体处理的任务越来越复杂，需要与用户进行大量的交互，这种能力对于提高效率和提升用户满意度都至关重要。

#### 流式
对于基于 LLM 构建的应用程序而言，流式传输对于提升其响应速度至关重要。通过逐步显示输出，即使在完全响应准备就绪之前也能实现，流式传输能够显著改善用户体验 (UX)，尤其是在处理 LLM 的延迟问题时。

#### 结构化输出
结构化输出允许代理以特定、可预测的格式返回数据。无需解析自然语言响应，即可获得类型化的结构化数据。



## 快速开始

准备工作

借用几个小示例，介绍一下langchain和langgraph

一个是RAG_agent、tool_agent
一个是投诉智能体助手



## 项目实战


## 如何进阶

可视化的调试框架：LangGraph Studio
用于本地启动、调试、测试和托管 LangGraph 智能体图的开发者命令行工具：LangGraph CLI 


学习原理，学习好的开源项目

deepflow mirimin


大模型串联整个工作流

大模型选型
方法论

## 讲解思路


大家好
今天我分享的主题是如何破局AI - 基于LangGraph智能体开发

可以看到标题做一些变化，
前端领域更狭窄一些

理论比较少，代码更多一下。

广进这里了解了模型的类型

PPT苦手找AI生成的PPT和配图
如果有不好的体验

---

不知道大家有没有和我一样的困扰，
在AI时代，如何去学习AI？如何上手AI产品开发？
通过搜索引擎，大家应该会得到类似下面这条学习路线

1. 学习Python
2. 学习数据基础：线性代数、微积分、概率统计
3. 学习机器学习：线性回归、决策树
4. 学习深度学习：神经网络、卷积神经网络、循环神经网络
5. 大模型训练、大模型参数微调
6. AI产品开发
   
作为一个非科班出生，毕业10年的开发者来说，这条学习路线过于艰深，让人工望而却步。

---

但是我们作为拥有多年开发经验的程序员，对业务和产品都有深刻的理解，对开发一款什么样的产品都有比较深刻的认知。
困扰我们的并不是上述这些理论，而是如何上手开发AI产品。

这不是否认上述学习路线，而是寻找一个更适合程序的的学习路线。及从实践出发，从项目出发，运用我们熟悉的技术栈快速构建AI产品，在开发过程中自上而下的补全AI理论知识。

---

所以我推荐现在大火的LangGraph框架，它可以帮助我们快速构建智能体，而且在上个月10月20号LangGraph团队正式发布了1.0版本，标志它已经可以用于生产级别的开发了。

选择LangGraph
在面对快速发展迭代的AI时代，框架提供了快速构建智能体的方法，让我无需爬山式的学习，快速上手AI产品开发。获取多巴胺。

收获
在这里你将了解LangGraph的底层原理和核心组件
实现一个约100行代码支持联网查询的ReAct Agent
获得将项目想法转换成智能的实战思路

---

什么是LangGraph?

说到LangGraph，不得不先提一下LangChain。

2022年10月, LangChain发布了自己首个稳定版本，其核心思想是模块化和链式编排，通过标准化的组件和链式工作流简化了早期LLM应用的开发。

在LangChain正式发布的下个月也就是2022年11月底大名鼎鼎的ChatGPT横空出世。

ChatGPT的横空出世，标志着AI时代的到来，也标志大模型能力的高速发展。很快大模型不仅拥有极强的工具识别和调用能力，同时还逐步支持多工具的并联和串联调用

LangChain链式工作流模式灵活性不足，已逐渐满足不了越来越复杂智能体的开发需求。

2024年2月，LangChain团队发布了LangGraph,

LangGraph的定位是底层编排，其核心思想是使用图架构设计工作流。它可以提供更细颗粒度的控制流。

2025年10月20号，LangGraph团队发布了1.0版本，标志其生态已成为可以满足企业生产级部署的智能体框架。

---

那么LangGraph和LangChain的关系和定位是什么？

首先经过1.0版本的重构，LangChain的的底层的链式结构已经完全被替换为，LangGraph的图结构的高级抽象。

它们之间的定位就很明确
- LangGraph是底层编排，提供长期运行、高可控、高扩展，的生产级智能体设计
- LangChain是上层应用开发，提供了一系列的组件和工具，帮助开发者快速构建智能体应用

它们最佳实践就是
1. 基于LangChain的createAgent预构建函数快速构建智能体。
2. 利用LangChain的核心组件和LangGraph的图结构工作流，构建复杂工作流和智能体系统。
  
---

LangGraph的核心思想

LangGraph最核心的思想就是图结构工作流
将项目的逻辑拆解为有向图，举个例子就是行内的BankGPT智能体应用的工作流

节点就包含模型调用、工具函数、条件判断
边就是节点之间的连接用于流程传递。

--- 

状态管理
是LangGraph整个流程的数据中心
共享数据结构：维护全局共享状态，供节点读写更新，实现节点间的信息传递
状态更新机制：保证每个节点返回状态更新，确保工作流数据连续性。
举个前端开发比较熟悉的例子：
VUE开发都用过Pinia或者Vuex这些全局状态管理库，在需要页面间的数据传递，可将数据更新到全局状态里，方便其它页面获取。

---

LangGraph原生就支持循环和条件分支，根据中间结果去实时调整执行路径

同时也支持重复执行和不同分支同时执行，适应复杂决策和试错的需求。

---

说完LangGraph核心功能组件后不得不提一下LangChain的核心组件。

模型：
模型是智能体的推理引擎。它们驱动智能体的决策过程，决定调用哪些工具、如何解释结果以及何时给出最终答案。
不同的模型擅长不同的任务，模型的质量和功能直接影响智能体的基本可靠性和性能，LangChain 集成几十家模型提供商供选择


消息：
消息是模型基本上下文单元，代表输入输出，携带对话状态内容和元数据，LangChain提供标准消息类型确保模型调用行为一致。


工具：
扩展智能体能力，提供搜索、计算、数据处理等函数调用。
定义输入输出，促进大模型与现实交互，增强模型功能。


记忆：
记忆系统记录过往交互，助AI学习反馈，适应用户偏好，提升复杂任务处理效率及满意度。
在复杂任务处理中，记忆能力对AI提升效率和用户满意度至关重要。


流式：
显著提升LLM应用响应速度，逐步显示输出，改善UX，尤其解决延迟问题。
未待完全响应即开始输出，即时反馈用户，优化交互体验，关键于LLM处理流程。


结构化输出
结构化输出允许大模型以特定、可预测的格式返回数据。无需解析自然语言响应，即可获得类型化的结构化数据


上面这些组件都是都是大家很熟悉的功能，LangChain只是将这些功能模块化组件化，方便调用。

---

下面我将演示快速搭建一个ReAct Agent智能体。

准备工作有

Node版本>=20
一个对话模型的API Key，我选择的是DeepSeek，token真的很便宜
一个搜索服务的API Key，我选择的是百度千帆的AI搜索。每天有100次调用的免费额度。

然后初始化一个Node项目

设置和环境变量 .env

准备一个入口文件和执行命令

---

