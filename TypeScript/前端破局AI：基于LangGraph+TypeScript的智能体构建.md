# 前端破局AI：基于LangGraph+TypeScript构建智能体

## 背景
不知道大家有没有跟我一样的问题，在这个AI时代，我们该如何学习AI？

打开搜索网站搜索如何学习AI？肯定会得到类似这样的流程

1. 学习Python
2. 学习线性代数、微积分、概率统计
3. 学习机器学习
4. 学习深度学习
5. 大模型训练
...

作为一个非相关专业，毕业10年之久的开发看到这些一脸懵，不用入门直接放弃。

并不是说这种学习路线不对，而是不适合我这样的工程师去学习。

作为开发人员在技术上我们更贴近业务和产品的应用层，而不是去研究更核心的底层原理。



项目需要快速完成AI功能迭代，这个时候直接上手智能体开发显然更具性价比。

所以我推荐LangGraph框架，从构建第一个智能体开始，提前感受 AI 开发的乐趣与成就感。
跳过爬山的过程，自上而下，从项目实践出发，在工作中逐步深挖原理。


在这里你将得到什么？

- 了解 LangGraph 核心原理和基础功能
- 快速搭建一个约 100 行代码的支持联网查询的智能体示例，可在终端交互运行
- 更多项目想法转换智能体的思路，可拓展的



结合国家发文，2027年，新一代智能终端、智能体等应用普及率要超过70%；到2030年，智能经济要成为中国经济发展的重要增长极。



## 什么是LangGraph？

#### 发展历程
要讲LangGraph不得不先说下LangCahain。
2022年10月，在OpenAI的ChatGPT正式发布前夕，LangChain发布了它的首个稳定版本。

其核心思想是模块化与链式编排，通过提供Prompt Templates、Models、Agents、Memory等标准化组件，并利用“链”将它们组合起来，极大地简化了早期LLM应用的开发流程。

随着大模型能力的飞速进化，大模型不仅拥有极强的工具识别和调用能力，同时还逐步支持多工具的并联和串联调用。LangChain链式工作流模式灵活性不足，已逐渐满足不了越来越复杂智能体的开发需求，于是在2024年2月LangChain团队发布了`LangGraph`，
`LangGraph`定位就是作为LangChain底层编排层，其核心采用图结构来设计工作流，提供更细粒度的控制流的同时添加了状态管理、流式处理、持久执行、记忆、人机交互等功能。

经过多年的迭代开发，2025年10月LangChain 团队正式发布 LangChain 1.0 与 LangGraph 1.0两大框架的首个主要版本，这个标志着LangChain生态已经是可满足企业级生产部署的智能体框架。


#### LangGraph与LangChain的关系
LangChain 1.0 版本对底层链式结构和代理进行了彻底的重构。所有链式结构和代理现在都替换为一个基于 LangGraph 构建的高级抽象。

自此LangChain和LangGraph的定位已经很明确了。

- LangGraph ：一个 底层运行时框架 ，专为需要长期运行、可控且高定制化的生产级智能体设计。
- LangChain ：是LangGraph的高级抽象，是构建 AI 智能体的 最快方式 。提供标准的工具调用架构、供应商无关设计和可插拔的中间件系统，让开发者高效构建通用 Agent。



LangGraph和LangChain的最佳实践
1. 基于LangChain的`createAgent`函数快速构建智能体
2. 将LangChain的核心组件作为LangGraph的“组件库”，通过LangGraph节点和边将这些组件组织编排在一起，构建一个复杂的工作流和智能体系统。


## LangGraph核心思想

LangGraph 的核心在于其采用了图架构来设计智能体的工作流程。LangGraph 将智能体执行任务的过程，抽象为一个由节点（Node）和边（Edge）构成的**有向循环图（Directed Cyclic Graph）**。

理解 LangGraph，可以抓住以下几个关键点：

- 图结构工作流：在 LangGraph 中，应用逻辑被建模成一个有向图，由“节点”和“边”组成。节点代表一个具体的操作步骤，例如调用大语言模型、执行一个工具函数或进行条件判断。边则定义了这些节点之间的连接关系和执行顺序。
- 状态管理：这是 LangGraph 的核心。它会维护一个贯穿整个图的共享数据结构（State）。每个节点都可以读取当前状态，并返回对状态的更新，使信息在多步骤工作流中有效传递与累积。
- 支持循环与分支：LangGraph 原生支持循环和条件分支。工作流可以根据中间结果“绕回去”重新执行某些步骤，或选择不同的执行路径，这对于需要反复试错或决策的场景至关重要。

核心组件：

#### 节点（Node）类型
- **LLM 调用节点**: 负责与大型语言模型进行交互，执行推理任务
- **工具调用节点**: 允许智能体调用外部工具或 API，扩展能力边界
- **自定义函数节点**: 封装业务逻辑或数据处理逻辑
- **子图节点**: 提高代码模块化和可维护性

#### 边（Edge）类型
- **普通边**: 定义节点间的直接顺序执行关系
- **条件边**: 根据状态动态决定工作流程走向
- **入口点**: 定义工作流程的起始位置
- **条件入口点**: 根据初始状态动态选择起始节点

#### 状态（State）
状态是 LangGraph 的核心概念，扮演着多重角色：
- **上下文信息存储**: 记录对话历史、任务进度等
- **节点间数据传递**: 作为共享的数据容器
- **状态持久化**: 支持记忆能力和容错恢复
- **多智能体共享**: 实现智能体间协作

## LangChain核心组件
同时我们还需要了解LangChain的核心组件

#### 模型
模型是智能体的推理引擎。它们驱动智能体的决策过程，决定调用哪些工具、如何解释结果以及何时给出最终答案。
您选择的模型的质量和功能直接影响智能体的基本可靠性和性能。不同的模型擅长不同的任务
LangChain 的标准模型接口可让您访问许多不同的提供商[集成](https://docs.langchain.com/oss/javascript/integrations/providers/overview)。


#### 消息
消息是模型的基本上下文单元。它们代表模型的输入和输出，携带与 LLM 交互时表示对话状态所需的内容和元数据。LangChain 提供了一种适用于所有模型提供程序的标准消息类型，确保无论调用哪个模型，行为都保持一致。

```typescript
const messages = [
  { role: "system", content: "You are a poetry expert" },
  { role: "user", content: "Write a haiku about spring" },
  { role: "assistant", content: "Cherry blossoms bloom..." },
];
import { SystemMessage, HumanMessage, AIMessage } from "langchain";

const messages = [
  new SystemMessage("You are a poetry expert"),
  new HumanMessage("Write a haiku about spring"),
  new AIMessage("Cherry blossoms bloom..."),
];

```

#### 工具
工具是智能体的扩展能力。它们提供了一系列的函数，智能体可以调用这些函数来完成特定的任务，如搜索、计算、数据处理等。
工具是大模型调用以执行操作的组件。它们通过定义明确的输入和输出，使大模型能够与世界进行交互，从而扩展模型的功能。

#### 记忆
 记忆系统能够记住以往交互的信息。对于人工智能体而言，记忆至关重要，因为它使它们能够记住之前的交互，从反馈中学习，并适应用户偏好。随着人工智能体处理的任务越来越复杂，需要与用户进行大量的交互，这种能力对于提高效率和提升用户满意度都至关重要。

#### 流式
对于基于 LLM 构建的应用程序而言，流式传输对于提升其响应速度至关重要。通过逐步显示输出，即使在完全响应准备就绪之前也能实现，流式传输能够显著改善用户体验 (UX)，尤其是在处理 LLM 的延迟问题时。

#### 结构化输出
结构化输出允许代理以特定、可预测的格式返回数据。无需解析自然语言响应，即可获得类型化的结构化数据。



## 快速开始

准备工作

借用几个小示例，介绍一下langchain和langgraph

一个是RAG_agent、tool_agent
一个是投诉智能体助手



## 项目实战


## 如何进阶

可视化的调试框架：LangGraph Studio
用于本地启动、调试、测试和托管 LangGraph 智能体图的开发者命令行工具：LangGraph CLI 


学习原理，学习好的开源项目

deepflow mirimin


